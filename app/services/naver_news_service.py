import asyncio
import httpx
from datetime import datetime
from bs4 import BeautifulSoup
from app.config import logger

nowtime = datetime.now().strftime("%Y%m%d")


async def get_naver_news_urls(code=101, page_num=1, date=nowtime):
    naver_news_category_code = code
    page_number = page_num
    set_date = date
    url_list = []

    try:
        logger.info(
            f"ğŸ”” ë‰´ìŠ¤ URL ìˆ˜ì§‘ ì‹œì‘ - ì¹´í…Œê³ ë¦¬: {naver_news_category_code}, í˜ì´ì§€: {page_number}, ë‚ ì§œ: {set_date}"
        )

        async with httpx.AsyncClient(follow_redirects=True) as client:
            for i in range(1, page_number + 1):
                try:
                    # êµ¬ ë„¤ì´ë²„ ê²½ì œ ê²½ë¡œ
                    # url = f'https://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1={naver_news_category_code}&date={set_date}&page={i}'
                    # ìƒˆ ë„¤ì´ë²„ ê¸€ë¡œë²Œ ê²½ì œ ì†ë³´ ê²½ë¡œ (262 = ê¸€ë¡œë²Œ ê²½ì œ ì½”ë“œ)
                    url = f"https://news.naver.com/breakingnews/section/{naver_news_category_code}/262?date={set_date}"
                    headers = {
                        "User-Agent": (
                            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                            "AppleWebKit/537.36 (KHTML, like Gecko) "
                            "Chrome/91.0.4472.124 Safari/537.36"
                        )
                    }

                    logger.info(
                        f"ğŸ“ ìš”ì²­ URL: {url}, í˜ì´ì§€: {i}/{page_number}"
                    )
                    response = await client.get(url, headers=headers)
                    if response.status_code != 200:
                        logger.error(
                            f"âŒ í˜ì´ì§€ {i} ìš”ì²­ ì‹¤íŒ¨: HTTP {response.status_code}"
                        )
                        continue

                    soup = BeautifulSoup(response.content, "html.parser")
                    # êµ¬ ë„¤ì´ë²„ DOM êµ¬ì¡°
                    # news_list = soup.select('.newsflash_body .type06_headline li dl')
                    # news_list.extend(soup.select('.newsflash_body .type06 li dl'))

                    news_list = soup.select(
                        ".section_article .sa_list .sa_item .sa_item_inner .sa_item_flex .sa_text"
                    )
                    logger.debug(
                        f"ğŸ“ í˜ì´ì§€ {i}ì—ì„œ {len(news_list)}ê°œì˜ ë‰´ìŠ¤ í•­ëª© ë°œê²¬"
                    )

                    for line in news_list:
                        a_tag = line.find("a")
                        if a_tag:
                            news_url = a_tag.get("href")
                            url_list.append(news_url)

                    # ìš”ì²­ ê°„ì— ì•½ê°„ì˜ ì§€ì—°
                    await asyncio.sleep(1)

                except Exception as e:
                    logger.error(f"âŒ í˜ì´ì§€ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    continue

        logger.info(
            f"âœ… ë‰´ìŠ¤ URL ìˆ˜ì§‘ ì™„ë£Œ - ì´ {len(url_list)}ê°œì˜ URL ìˆ˜ì§‘ë¨"
        )
        return url_list

    except Exception as e:
        logger.error(f"âŒ ë‰´ìŠ¤ URL ìˆ˜ì§‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return url_list


# ë‰´ìŠ¤ URL ë‚´ë¶€ì˜ ìƒì„¸ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
async def get_naver_news_content(url: str, client: httpx.AsyncClient):
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/91.0.4472.124 Safari/537.36"
        )
    }
    try:
        logger.debug(f"ğŸ“ ë‰´ìŠ¤ ìƒì„¸ ë‚´ìš© ìš”ì²­: {url}")
        response = await client.get(url, headers=headers)
        if response.status_code != 200:
            logger.error(
                f"âŒ ë‰´ìŠ¤ ìƒì„¸ ë‚´ìš© ìš”ì²­ ì‹¤íŒ¨: {url} - HTTP {response.status_code}"
            )
            return None

        soup = BeautifulSoup(response.content, "html.parser")
        # ì œëª© ì¶”ì¶œ: h2 íƒœê·¸ ë‚´ë¶€ì˜ span íƒœê·¸ ì„ íƒ (ì–‘ìª½ ê³µë°± ì œê±°)
        title_tag = soup.select_one("h2 > span")
        title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"

        article = soup.find("article", {"id": "dic_area"})
        content = article.get_text(strip=True) if article else "ë³¸ë¬¸ ì—†ìŒ"

        news_data = {
            "url": url,
            "title": title,
            "content": content,
        }
        logger.debug(f"ğŸ“ ë‰´ìŠ¤ ìƒì„¸ ë‚´ìš© ì¶”ì¶œ ì„±ê³µ: {url}")
        return news_data

    except Exception as e:
        logger.error(f"âŒ ë‰´ìŠ¤ ë‚´ìš© ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {url} - {e}")
        return None


async def get_naver_news_contents():
    news_urls = await get_naver_news_urls()
    news_contents = []
    async with httpx.AsyncClient() as client:
        tasks = [get_naver_news_content(url, client) for url in news_urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for result in results:
            if isinstance(result, Exception):
                logger.error(
                    f"âŒ get_naver_news_content ì‘ì—…ì—ì„œ ì˜ˆì™¸ ë°œìƒ: {result}"
                )
            elif result:
                news_contents.append(result)
    logger.info(
        f"âœ… ë‰´ìŠ¤ ìƒì„¸ ë‚´ìš© ìˆ˜ì§‘ ì™„ë£Œ - ì´ {len(news_contents)}ê°œì˜ ë‰´ìŠ¤ ë‚´ìš© ìˆ˜ì§‘ë¨"
    )
    return news_contents
